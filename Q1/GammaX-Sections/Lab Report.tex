\documentclass[letter]{article}
	% basic article document class
	% use percent signs to make comments to yourself -- they will not show up.

\usepackage{changepage}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
	% packages that allow mathematical formatting

\usepackage{graphicx}
	% package that allows you to include graphics
	
\usepackage{pgfplots}
\usepackage{subfig}


\usepackage{siunitx}


\usepackage{setspace}
	% package that allows you to change spacing

\onehalfspacing
	% text become 1.5 spaced

\usepackage{fullpage}
	% package that specifies normal margins
	
%\makeatletter
%\newcommand{\xRightarrow}[2][]{\ext@arrow 0359\Rightarrowfill@{#1}{#2}}
%\makeatother

\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\DeclareMathOperator{\SPAN}{span}
\DeclareMathOperator{\HESS}{Hess}
\DeclareMathOperator{\DIAM}{diam}
\newcommand{\PD}[2][]{\frac{ \partial {#1} }{ \partial {#2} } }
\newcommand{\BVEC}[1]{\boldsymbol{#1}}
\newcommand{\CONTRA}{\Rightarrow\!\Leftarrow}


%hyperref-compatible custom float tagging. Place command before caption
\makeatletter \newcommand{\floattag}[1]{
   \@namedef{the\@captype}{#1}%
   \@namedef{theH\@captype}{#1}%
   \addtocounter{\@captype}{-1}} 
\makeatother


\usepackage{graphicx}
\graphicspath{ {C:/Users/jdewh/OneDrive - The University of Chicago/Third Year/PHYS 211/Q1/GammaX-Sections/} }
\usepackage{lipsum}

\newcommand{\X}{\mathbf{x}}
\newcommand{\Y}{\mathbf{y}}
\newcommand{\BV}[1]{\hat{\mathbf{#1}}}
\newcommand{\IP}[1]{\langle #1 \rangle}

%a ~ can replace a space in text mode to prevent a line break at that space.

\begin{document}
	% line of code telling latex that your document is beginning

%Title section
\begin{center}
	{\large PHYS 211 Gamma Cross-Sections Lab Report}
	
	Jack Dewhurst \hspace{1cm}
	25 October 2021
	
	\vspace{5mm}
\end{center}
	
%end title section


\section{Spectral Analysis of Na-22}

\subsection{Full Spectrum and Visible Features}
\begin{figure}[h] \centering
    \includegraphics[scale=.5]{Na-Spectrum.png}
    \caption{A full decay spectrum of Na-22 up to approximately \qty{1350}{\kilo\electronvolt}, taken over \qty{178}{\second}. Each detector channel corresponds to an energy of approximately 1.3keV. Visible are three main regions of activity: channels 10 to 250, comprising the Compton shelf of the \qty{511}{\kilo\electronvolt} full-energy peak and the backscatter peaks of both full-energy peaks; channels 350 to 425, comprising the full-energy peak at \qty{511}{\kilo\electronvolt}; and channels 880 to 970, comprising the full-energy peak at \qty{1270}{\kilo\electronvolt}.}
    \label{fig:NaFullSpec}
\end{figure}

Figure (\ref{fig:NaFullSpec}) shows a full decay spectrum of sodium-22. The relationship between detector channel and photon energy is arbitrary, though, so some determination of energy scale was necessary. For the two visible Gaussian peaks, the peak energies agreed with the expected 1270:511 ratio of energies, which led us to conclude that the two clear peaks in the spectrum were the emission peaks we expected.

We then chose our regions of interest for each full-energy peak to include the entire bell curve and approximately 10 channels of both tails of the peak. The software reported both net and gross counts for each region of interest, with the net count having automatically filtered out the background noise in the counts. However, for this filtering to work properly, the regions of interest needed to have some channels of background noise on each end. We limited our padding to roughly 10 channels on each side in order to limit the amount of spurious noise introduced to each region of interest. This choice will be explained somewhat more fully in the discussion of our uncertainties.

 Visible in particular are full-energy peaks at \qty{511}{\kilo\electronvolt} and \qty{1270}{\kilo\electronvolt}, as well as Compton edges for each peak. The Compton shelf for the higher-energy peak is notably less visible, due both to the fact that the higher-energy emission occurs less frequently than the \qty{511}{\kilo\electronvolt} emission and to the fact that higher-energy gamma rays tend to be scattered less than low-energy rays. The second backscatter peak is not visually distinguishable from scattering noise, but its position can be predicted from the relationship $E_\gamma = E_{CE} + E_{BS}$, where $E_\gamma$ is the energy of the photon, $R_{CE}$ is the energy at the Compton edge, and $E_{BS}$ is the energy of the backscatter peak. This relationship is a result of the geometry of the setup, as the backscatter peak is from photons that scatter once (presumably off of the lab bench) and then enter the detector and deposit the energy that remains after a 180 degree deflection, whereas photons in the Compton shelf deposit only the energy \textit{lost} in a deflection, with the maximal deflection of 180 degrees appearing as the Compton edge. Since the full-energy peak and the Compton edge are fully visible for the \qty{1270}{\kilo\electronvolt} mode, we can examine the predicted location of a backscatter peak and we find what appears to be a small peak, but could simply be noise. 

\subsection{Modeling the 511 keV Full-Energy Peak}

To examine more closely the shape of the \qty{511}{\kilo\electronvolt} full-energy peak, we used a least-squares regression to fit a Gaussian distribution with linear background to the full-energy peak, as shown in figure (\ref{fig:NaSpecRestr}).

\begin{figure}[h] \centering
    \includegraphics[scale=.5]{Na-Spectrum Restricted.png}
    \caption{The same spectrum of Na-22, shown from channels 350 to 425. Each point is plotted with Poissonian error $\Delta k = \sqrt{k}$. Also shown are a Gaussian function fit to the full-energy peak, the fit parameters, and the linear background term as determined by the least-squares regression.}
    \label{fig:NaSpecRestr}
\end{figure}

We expect the count rates over a given time to obey Poissonian statistics, so for a channel with $k$ counts we find the error to be $\sqrt{k}$. The function used for the regression was given by
\begin{align}
N(x)
&=
\frac{A}{\sigma \sqrt{2 \pi}} \exp \left( \frac{- (x-\mu)^2}{2 \sigma^2} \right) + bx + c
\end{align}

where in this case $x$ represents the channel number, and $N(x)$ the expected number of counts on that channel. The determined parameters for the centroid, standard deviation, total counts, and linear background, as well as the uncertainties therein, may be found in figure (\ref{fig:NaSpecRestr}). We find the reduced chi-squared value on this fit to be 1.25, which suggests that the Gaussian function with linear background does model the data well.

Also plotted in figure (\ref{fig:NaSpecRestr}) is the linear background as determined by the fitting function. This background term would be expected to come from two main sources: the Compton shelf of the \qty{1270}{\kilo\electronvolt} emission process; and laboratory noise, particularly other gamma ray sources such as samples from other groups in the same room. In principle, there is no reason for this background to be linear, but based on a spectrum taken with no sample, we concluded that above approximately \qty{300}{\kilo\electronvolt} the laboratory background could be reasonable modeled as linear. However, we could not measure only the portion of the background radiation due to scattering of the \qty{1270}{\kilo\electronvolt} photons, so the background is likely not entirely linear. This non-linearity has particular ramifications for the uncertainties in our measured photon counts, which will be discussed in more detail in section \ref{sss:SysError}.


\section{Linear Attenuation Coefficients}

\subsection{Formulae, Uncertainties, and Statistical Error}

\subsubsection{Dominant Sources of Systemic Error} \label{sss:SysError}

The primary source of error in our experiment was introduced by the method of discriminating between background counts and actual transmitted gamma rays. We used the system that the provided software supported natively, which essentially draws a line between the counts at each end of the region of interest. It then reports all counts above this line as `net counts', as well as the total gross count in the region of interest. This is analogous to discarding all data below the gray dashed line in figure (\ref{fig:NaSpecRestr}) for purposes of computation.

Our choice of padding in our region of interest would essentially affect our ability to discriminate between background and net photon counts. In general, we found the background detection to be convex, so picking a large amount of padding around each region of interest would mean both throwing away more useful data \textit{and} introducing spurious background counts that would add to our statistical error. We chose roughly 10 channels as padding to minimize this effect without the software considering parts of our Gaussian regions as background.

The other primary systemic source of error in our system would be caused by other students moving radioactive sources nearby. For instance, if someone carried a sodium button source past us while we were taking data on sodium, it would add false counts to our data. We tried to mitigate this effect by simply not taking data while people were moving around in the lab, but there is likely some distortion from other groups in the same room.

Some systemic error was likely introduced also by the case of the photodetector: the PMT and NaI crystals were enclosed within a sheet of aluminum. This thin layer of shielding should, at each photon energy, result in a constant decrease in scale of the measured counts. However, we are unable to quantify this effect or verify that it is, in fact, uniform. 

Dead times in the detector could also have introduced some systemic error, particularly in the higher count-rate samples. However, the software reported the total dead time as less than the uncertainty in the time measurement, so this effect should be minor.


\subsubsection{Statistical Error in Measurement}

We took three classes of measurement over the course of the experiment: thickness of shielding, time elapsed in measurement, and photons counted. In all cases, we measured the thickness of the shielding with precision calipers rated to \qty{0.05}{\mm}, so the error in shielding thickness was negligible compared to the other two sources.

The software reported the live time of the measurement to the second, so our time uncertainty for all measurements is simply \qty{0.5}{\s}.

As previously mentioned, the photon counts are expected to obey Possonian statistics, so the uncertainty in the photon count $k$ is given by $\sqrt{k}$. 

\subsubsection{Data Analysis and Error Propagation}

In order to calculate an attenuation coefficient $\lambda$ for each sample, we fitted an exponential decay function with constant background (representing background radiation that does not vary with shielding thickness) to model transmitted count rate as a function of shielding thickness.

To calculate the transmitted count rate for each sample we took the net counts as reported by the software and divided by the reported live time:
\begin{equation}
R = \frac{N}{t}
\end{equation}
The software calculates the net count as $N = G - B$ where $G$ is the gross count and $B$ is the background count, which it determines by the method described in section \ref{sss:SysError}. However, both the net and background terms are Poissonian, so they have errors given by
\begin{align}
\Delta G &= \sqrt{G} \\
\Delta B &= \sqrt{B} = \sqrt{G - N}
\end{align}
The error in the net count can then be found by
\begin{align}
\Delta N 
&= 
\sqrt{ (\Delta G)^2 + (\Delta B)^2 - 2 \sigma_{GB}}
=
\sqrt{ G + G - N - 2 \sigma_{GB}}
\end{align}
where $\sigma_{GB}$ is the covariance of the gross and background counts. The covariance will be positive (increasing the background counts causes to the gross count to increase), but we have no way to estimate it numerically, leaving us to overestimate the error:
\begin{align}
\Delta N &\approx \sqrt{2G - N}
\end{align} 
The count rate and its uncertainty are then found by
\begin{equation}
R = \frac{N}{t}
\end{equation}
\begin{equation}
\Delta R = R \sqrt{ \left( \frac{\Delta N}{N} \right)^2 + \left( \frac{\Delta t}{t} \right)^2}
\end{equation}


\subsection{Empirically Determined Attenuation Coefficients}

For each radioactive sample, we took data at several shielding thicknesses for each major energy peak. From these, we fit an exponential decay function with constant background. We then extract the attenuation coefficient and its error from the fit parameters. Below are presented the fit function for each peak as well as the attenuation coefficients.

\begin{figure}[h] \centering
    \includegraphics[scale=.5]{Na-Attenuation.png}
    \caption{The measured transmission rate for each peak of the Na-22 sample at various thicknesses of aluminum shielding, as well as an exponential decay with constant background fitted to the data.}
    \label{fig:NaAtten}
\end{figure}

In figure \ref{fig:NaAtten} we observe relatively large reduced chi-squared values. There is no obvious pattern in the residuals to suggest that the exponential with constant background is a poor fit function. The high reduced chi-squared then suggests that there was significant noise in the measurements. This may be because we tested the sodium sample first, when the lab was relatively busy --- other lab groups were moving samples around more at the beginning of the lab section than later on.

\begin{figure}[h] \centering
    \includegraphics[scale=.5]{Cs-Attenuation.png}
    \caption{The measured transmission rate for each peak of the Cs-137 sample at various thicknesses of aluminum shielding, as well as an exponential decay with constant background fitted to the data.}
    \label{fig:CsAtten}
\end{figure}

Figure \ref{fig:CsAtten} shows the data taken for the cesium samples. We found in taking data that for the \qty{31}{\kilo\electronvolt} process, the spectrum was too noisy to determine a peak beyond \qty{7}{\mm} of shielding.

\begin{figure}[h] \centering
    \includegraphics[scale=.5]{Ba-Attenuation.png}
    \caption{The measured transmission rate for each peak of the Ba-133 sample at various thicknesses of aluminum shielding, as well as an exponential decay with constant background fitted to the data. Note that the long tail of small values results in a very high chi-squared value at low energies.}
    \label{fig:BaAtten}
\end{figure}

Figure \ref{fig:BaAtten} shows a similar effect as we found for cesium, in that the data for the \qty{31}{\kilo\electronvolt} process becomes completely attenuated at high shielding thickness. In this case, the spectrum was somewhat less noisy, so we still included those points in the data fitting. However, the very small values at the tail of the exponential function still result in a very high reduced chi-squared value for that sample.


\subsection{Comparison with NIST Values}

One of the goals of this experiment was to compare our empirical findings with the literature values for linear attenuation published by the National Institute of Standards and Technology (NIST). We used the provided files of linear attenuation coefficients for aluminum at various energy levels. In cases in which the provided energy values did not match the energies used in our experiment, we found a `literature' value by simple linear interpolation between two adjacent data points.

We present our values of linear attenuation coefficients against the NIST values in table \ref{tab:NISTComp}.

\begin{table}[h] 
\centering  \begin{tabular}{ c  c  c  c  c  }
Energy (\unit{\kilo\electronvolt}) & $\lambda_E$ (\unit{\per\mm}) & $\lambda_N$ (\unit{\per\mm}) \\ [.25em]
\hline 
31 (Cs) & 0.365 & 0.279 \\
31 (Ba) & 0.213 & 0.279 \\
81 & 0.0488 & 0.0541 \\
356 & 0.0290 & 0.0266 \\
511 & 0.0196 & 0.0226 \\
662 & 0.0187 & 0.0202 \\
1270 & 0.0185 & 0.0147
\end{tabular}
\caption{Empirical attenuation coefficients ($\lambda_E$) against NIST values ($\lambda_N$) at various energies. The two samples taken at \qty{31}{\kilo\electronvolt} are marked with the element used for that sample.}
\label{tab:NISTComp}
\end{table}

To determine the consistency of our results with the literature values, we calculate for each energy a value of $t$, which we define as
\begin{align}
t
&=
\frac{\lambda_E - \lambda_N}{\sqrt{ (\Delta \lambda_E)^2 + (\Delta \lambda_N)^2 }}
\end{align}
We will consider each empirical attenuation coefficient consistent with the literature for $|t| \leq 1$, inconsistent with the literature for $|t| \geq 3$, and inconclusive otherwise. The values are presented in table \ref{tab:tValues}.

\begin{table}[h] 
\centering  \begin{tabular}{ c  c  c  c  c  } 
Energy (\unit{\kilo\electronvolt}) & $\Delta \lambda_E$ (\unit{\per\m}) & $\Delta \lambda_N$ (\unit{\per\m}) & $t$ & Interpretation  \\ \hline
31 (Cs) & 55 & 8.4 & 1.6 & Inconclusive \\ 
31 (Ba) & 2.5 & 8.4 & -7.5 & Inconsistent \\
81 & 1.1 & 1.6 & -2.6 & Inconclusive \\
356 & 1.2 & 0.80 & 1.6 & Inconclusive \\
511 & 0.58 & 0.68 & -3.4 & Inconsistent \\
662 & 2.1 & 0.61 & -0.69 & Consistent \\
1270 & 1.65 & 0.44 & 2.2 & Inconclusive 
\end{tabular}
\caption{Uncertainties in empirical and reference attenuation coefficients. Notice that uncertainties are reported here in \unit{\per\m}, not \unit{\per\mm}. Values of $t$ are also shown, as well as the interpretation of the meaning of the $t$ value.}
\label{tab:tValues}
\end{table}

Our data appear from this metric very inconsistent with the reference values. However, we note that the difference between the minimum and maximum of our values of $t$ is 9.7, which suggests that there is not a simple systemic disagreement between our data and the reference data.

We also note that the largest value of $|t|$, 7.5, comes from the lowest-energy emission from Ba-133, which did not achieve a very good fit. This sample does not appear to be representative of the group, and if we omit that datum, our $t$ values appear thoroughly inconclusive.

In order to visualize how our data compare to the values reported by NIST, we also include figure \ref{fig:AttenComp}. We can see that our data are close to those reported by NIST over the full range, but that our data are much more inconsistent than one might conclude from their errors alone. This suggests that we have systemically underestimated the errors in our experiment.

\begin{figure}[h] \centering
    \includegraphics[scale=.5]{AttenuationComparison.png}
    \caption{Our measured attenuation coefficients plotted against the NIST reported values. Per the wiki instructions, we have simply used a 3\% error on the NIST data.}
    \label{fig:AttenComp}
\end{figure}




\end{document}
	% line of code telling latex that your document is ending. If you leave this out, you'll get an error
